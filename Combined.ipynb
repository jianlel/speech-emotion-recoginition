{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50834213-fcfa-4c7b-a693-03e3500a6beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Audio, DatasetDict, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0ef97e9-f610-4cb9-a726-c2e212c07fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_labels(batch):\n",
    "    batch[\"emotion\"] = [sentiment for sentiment in batch[\"emotion\"]]\n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6288647-4ed3-465a-8ba3-0a81a92b1cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5796f7c91fa543ff9dbb9afc79a89abe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/1976 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "combined_dataset = load_dataset(\"./dataset/combined\", data_dir=\"./\", split=\"train\")\n",
    "features = combined_dataset.features.copy()\n",
    "features[\"emotion\"] = ClassLabel(names=['happy','neutral','angry','sad','fearful','disgust','calm','surprised','boredom'])\n",
    "combined_dataset = combined_dataset.map(adjust_labels, batched=True, features=features)\n",
    "combined_dataset = combined_dataset.train_test_split(test_size=0.2,stratify_by_column=\"emotion\")\n",
    "test_data_split = combined_dataset[\"test\"].train_test_split(test_size=0.5,stratify_by_column=\"emotion\")\n",
    "combined_dataset = DatasetDict({\n",
    "    \"train\": combined_dataset[\"train\"],\n",
    "    \"test\": test_data_split[\"test\"],\n",
    "    \"val\": test_data_split[\"train\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3899247-b4c5-4175-a45c-5ac3c714c8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoFeatureExtractor\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"facebook/wav2vec2-large-xlsr-53\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28291ff9-3d2d-4115-bc07-a64f615fce50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    audio_arrays = [x[\"array\"] for x in examples[\"audio\"]]\n",
    "    inputs = feature_extractor(\n",
    "        audio_arrays, sampling_rate=feature_extractor.sampling_rate\n",
    "    )\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c27ca13-154b-42de-86d4-3a992a808e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dataset = combined_dataset.cast_column(\"audio\", Audio(sampling_rate=16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65b7064-7b32-46ce-ad7c-5e4ac605b962",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16f6449f-2574-4531-a658-650b38d84c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = combined_dataset[\"train\"].features[\"emotion\"].names\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = str(i)\n",
    "    id2label[str(i)] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1458d5c2-2088-4d04-a4d6-3fd9f697b053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f8bb191eee44d5bb041e1cfc6aa594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1580 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f77489c040f64d08a439df87dcbc90c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/198 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "171ba2c5761d4c8e96328e39fa05d635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/197 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'input_values', 'attention_mask'],\n",
       "        num_rows: 1580\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'input_values', 'attention_mask'],\n",
       "        num_rows: 198\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['label', 'input_values', 'attention_mask'],\n",
       "        num_rows: 197\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_combined_dataset = combined_dataset.map(preprocess_function, remove_columns=\"audio\", batched=True)\n",
    "encoded_combined_dataset = encoded_combined_dataset.rename_column(\"emotion\", \"label\")\n",
    "encoded_combined_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efcde0eb-1886-47c2-84b8-6589e17d4ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2001615f-9e24-497c-9889-381b4268ddea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=eval_pred.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0905a63f-af0c-4778-8e5f-485cf0903f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-large-xlsr-53 and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForAudioClassification, TrainingArguments, Trainer\n",
    "\n",
    "num_labels = len(label2id)\n",
    "model = AutoModelForAudioClassification.from_pretrained(\n",
    "    \"facebook/wav2vec2-large-xlsr-53\", num_labels=num_labels, label2id=label2id, id2label=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa525841-71f7-431d-8ea6-9c4d24de6c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wkwon\\anaconda3\\envs\\dlnn\\Lib\\site-packages\\accelerate\\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4925' max='4925' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4925/4925 28:15, Epoch 24/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.166500</td>\n",
       "      <td>2.140993</td>\n",
       "      <td>0.162437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.677900</td>\n",
       "      <td>1.672525</td>\n",
       "      <td>0.340102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.015200</td>\n",
       "      <td>0.858021</td>\n",
       "      <td>0.685279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.835600</td>\n",
       "      <td>0.413865</td>\n",
       "      <td>0.893401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.390200</td>\n",
       "      <td>0.301223</td>\n",
       "      <td>0.934010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.231800</td>\n",
       "      <td>0.666462</td>\n",
       "      <td>0.873096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.507100</td>\n",
       "      <td>0.353614</td>\n",
       "      <td>0.923858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.172200</td>\n",
       "      <td>0.179738</td>\n",
       "      <td>0.959391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.166400</td>\n",
       "      <td>0.334996</td>\n",
       "      <td>0.939086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.079900</td>\n",
       "      <td>0.285123</td>\n",
       "      <td>0.949239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.247471</td>\n",
       "      <td>0.954315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.271130</td>\n",
       "      <td>0.954315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.256968</td>\n",
       "      <td>0.954315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4925, training_loss=0.5267856774605376, metrics={'train_runtime': 1696.8494, 'train_samples_per_second': 23.278, 'train_steps_per_second': 2.902, 'total_flos': 4.876366232802485e+18, 'train_loss': 0.5267856774605376, 'epoch': 24.94})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"combined_new_emotion_model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=0.0001,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=2,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=25,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    push_to_hub=False,\n",
    "    \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_combined_dataset[\"train\"].with_format(\"torch\"),\n",
    "    eval_dataset=encoded_combined_dataset[\"val\"].with_format(\"torch\"),\n",
    "    tokenizer=feature_extractor,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b409a4aa-e33b-4cfb-b586-28eda66edf5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6186405420303345,\n",
       " 'eval_accuracy': 0.8838383838383839,\n",
       " 'eval_runtime': 3.7204,\n",
       " 'eval_samples_per_second': 53.22,\n",
       " 'eval_steps_per_second': 13.439,\n",
       " 'epoch': 24.94}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(encoded_combined_dataset[\"test\"].with_format(\"torch\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b3389bd-84f6-44d3-8d7c-30640be1893d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined_new_emotion_model\\checkpoint-2962\n"
     ]
    }
   ],
   "source": [
    "best_ckpt_path = trainer.state.best_model_checkpoint\n",
    "print(best_ckpt_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
